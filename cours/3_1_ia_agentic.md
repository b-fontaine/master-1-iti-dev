# Intelligence Artificielle Agentique : Histoire, Fonctionnement et Techniques de Prompting

![](./images/3_1_visual.png)

## Table des matiÃ¨res

1. [Histoire de l'IA et des agents IA](#1-histoire-de-lia-et-des-agents-ia)
2. [Fonctionnement des agents IA](#2-fonctionnement-des-agents-ia)
3. [Architecture et diagrammes](#3-architecture-et-diagrammes)
4. [Techniques de prompting](#4-techniques-de-prompting)
5. [Applications en robotique](#5-applications-en-robotique)
6. [Ressources et rÃ©fÃ©rences](#6-ressources-et-rÃ©fÃ©rences)

---

## 1. Histoire de l'IA et des agents IA

### 1.1 Les origines de l'intelligence artificielle (1943-1956)

#### Les prÃ©curseurs thÃ©oriques

L'histoire de l'intelligence artificielle commence bien avant l'invention des ordinateurs modernes, avec des rÃ©flexions philosophiques sur la nature de l'intelligence et de la pensÃ©e.

**Dates clÃ©s :**

- **1943** : Warren McCulloch et Walter Pitts publient "A Logical Calculus of the Ideas Immanent in Nervous Activity", dÃ©crivant le premier modÃ¨le mathÃ©matique d'un neurone artificiel
- **1950** : Alan Turing publie "Computing Machinery and Intelligence" et propose le cÃ©lÃ¨bre **Test de Turing**
- **1951** : Marvin Minsky et Dean Edmonds construisent **SNARC**, le premier rÃ©seau de neurones artificiel

#### La confÃ©rence de Dartmouth (1956)

L'**Ã©tÃ© 1956** marque la naissance officielle de l'IA comme discipline scientifique. John McCarthy organise la **ConfÃ©rence de Dartmouth** avec :

- **John McCarthy** : inventeur du terme "Intelligence Artificielle" et du langage LISP
- **Marvin Minsky** : co-fondateur du MIT AI Lab
- **Claude Shannon** : pÃ¨re de la thÃ©orie de l'information
- **Allen Newell et Herbert Simon** : crÃ©ateurs du Logic Theorist, premier programme d'IA

> "Nous proposons qu'une Ã©tude de deux mois sur l'intelligence artificielle soit menÃ©e [...] L'Ã©tude doit procÃ©der sur la base de la conjecture que chaque aspect de l'apprentissage ou toute autre caractÃ©ristique de l'intelligence peut en principe Ãªtre dÃ©crit si prÃ©cisÃ©ment qu'une machine peut Ãªtre faite pour le simuler."
> â€” Proposition de la confÃ©rence de Dartmouth, 1955

### 1.2 L'Ã¢ge d'or et les premiers systÃ¨mes (1956-1974)

#### Les premiers succÃ¨s

**Programmes emblÃ©matiques :**

- **1956** : **Logic Theorist** (Newell & Simon) - prouve des thÃ©orÃ¨mes mathÃ©matiques
- **1958** : **LISP** (McCarthy) - premier langage de programmation pour l'IA
- **1961** : **Unimate** - premier robot industriel (General Motors)
- **1964** : **ELIZA** (Weizenbaum) - premier chatbot simulant un psychothÃ©rapeute
- **1966** : **SHRDLU** (Winograd) - comprend le langage naturel dans un monde de blocs
- **1969** : **Shakey** (SRI) - premier robot mobile autonome

**Shakey le robot** est particuliÃ¨rement important pour les Ã©tudiants en robotique : c'est le premier systÃ¨me Ã  combiner perception, planification et action de maniÃ¨re intÃ©grÃ©e.

#### L'optimisme initial

Cette pÃ©riode est caractÃ©risÃ©e par un **optimisme dÃ©bordant** :

- Herbert Simon prÃ©dit en 1965 : "Dans 20 ans, les machines seront capables de faire tout travail qu'un homme peut faire"
- Marvin Minsky dÃ©clare en 1970 : "Dans 3 Ã  8 ans, nous aurons une machine avec l'intelligence gÃ©nÃ©rale d'un Ãªtre humain moyen"

### 1.3 Le premier hiver de l'IA (1974-1980)

#### Les limites rÃ©vÃ©lÃ©es

Le **rapport Lighthill** (1973) au Royaume-Uni critique sÃ©vÃ¨rement les promesses non tenues de l'IA :

**ProblÃ¨mes identifiÃ©s :**

- **Explosion combinatoire** : les problÃ¨mes rÃ©els sont trop complexes
- **Manque de sens commun** : les systÃ¨mes ne comprennent pas le contexte
- **Limites du traitement symbolique** : difficultÃ© Ã  gÃ©rer l'incertitude
- **ProblÃ¨me du cadre** (frame problem) : comment reprÃ©senter ce qui ne change pas ?

**ConsÃ©quences :**

- RÃ©duction drastique des financements
- Abandon de nombreux projets
- Scepticisme gÃ©nÃ©ralisÃ© envers l'IA

### 1.4 Les systÃ¨mes experts (1980-1987)

#### Renaissance de l'IA

Les **systÃ¨mes experts** relancent l'intÃ©rÃªt pour l'IA en se concentrant sur des domaines spÃ©cifiques :

**SystÃ¨mes emblÃ©matiques :**

- **MYCIN** (1976) : diagnostic mÃ©dical des infections bactÃ©riennes
- **DENDRAL** (1965-1981) : analyse de spectres de masse en chimie
- **R1/XCON** (1980) : configuration d'ordinateurs chez DEC (Ã©conomies de 40M$/an)
- **PROSPECTOR** (1983) : exploration gÃ©ologique

**CaractÃ©ristiques des systÃ¨mes experts :**

- Base de connaissances (rÃ¨gles SI-ALORS)
- Moteur d'infÃ©rence
- Interface utilisateur
- Module d'explication

**Limites :**

- Acquisition des connaissances difficile ("knowledge bottleneck")
- Maintenance coÃ»teuse
- FragilitÃ© face aux cas non prÃ©vus
- Pas d'apprentissage automatique

### 1.5 Le deuxiÃ¨me hiver de l'IA (1987-1993)

#### L'effondrement du marchÃ©

**Causes :**

- Ã‰chec des machines LISP face aux PC
- CoÃ»ts de maintenance des systÃ¨mes experts
- Promesses non tenues (encore)
- Fin du projet japonais de 5Ã¨me gÃ©nÃ©ration

**PÃ©riode de transition :**

- DÃ©veloppement discret des rÃ©seaux de neurones
- Ã‰mergence des mÃ©thodes statistiques
- Travaux fondamentaux sur l'apprentissage automatique

### 1.6 L'Ã¨re de l'apprentissage automatique (1993-2011)

#### Nouveaux paradigmes

**Ã‰volutions majeures :**

- **1997** : **Deep Blue** (IBM) bat Garry Kasparov aux Ã©checs
- **1997** : DÃ©veloppement des **Support Vector Machines** (SVM)
- **2002** : **Roomba** - premier robot aspirateur grand public
- **2004** : **DARPA Grand Challenge** - vÃ©hicules autonomes
- **2006** : Geoffrey Hinton relance les rÃ©seaux de neurones profonds
- **2011** : **Watson** (IBM) gagne Ã  Jeopardy!

**Changement de paradigme :**

- De la programmation explicite Ã  l'**apprentissage Ã  partir des donnÃ©es**
- Des rÃ¨gles symboliques aux **modÃ¨les statistiques**
- De l'IA gÃ©nÃ©rale Ã  l'**IA spÃ©cialisÃ©e**

### 1.7 La rÃ©volution du Deep Learning (2012-2022)

#### Le tournant AlexNet

**2012** marque un tournant avec **AlexNet** qui remporte ImageNet avec une marge spectaculaire grÃ¢ce aux rÃ©seaux de neurones convolutifs (CNN) et aux GPU.

**AvancÃ©es majeures :**

- **2014** : **GANs** (Generative Adversarial Networks) - Ian Goodfellow
- **2015** : **ResNet** - rÃ©seaux trÃ¨s profonds (152 couches)
- **2016** : **AlphaGo** (DeepMind) bat Lee Sedol au Go
- **2017** : **Transformer** - architecture rÃ©volutionnaire ("Attention is All You Need")
- **2018** : **BERT** (Google) - comprÃ©hension du langage
- **2019** : **GPT-2** (OpenAI) - gÃ©nÃ©ration de texte
- **2020** : **GPT-3** - 175 milliards de paramÃ¨tres
- **2021** : **DALL-E** - gÃ©nÃ©ration d'images Ã  partir de texte
- **2022** : **ChatGPT** - IA conversationnelle grand public

### 1.8 L'Ã¨re des agents IA (2023-prÃ©sent)

#### L'Ã©mergence de l'IA agentique

**2023-2025** marque l'avÃ¨nement des **agents IA** capables d'agir de maniÃ¨re autonome :

**Jalons importants :**

- **Mars 2023** : **GPT-4** avec capacitÃ©s de raisonnement avancÃ©es
- **Avril 2023** : **Auto-GPT** - premier agent IA autonome populaire
- **Mai 2023** : **Voyager** (NVIDIA) - agent IA jouant Ã  Minecraft
- **Novembre 2023** : **GPTs** d'OpenAI - agents personnalisables
- **2024** : Explosion des frameworks d'agents (LangChain, AutoGen, CrewAI)
- **2024** : **Claude** (Anthropic) avec capacitÃ©s d'utilisation d'outils
- **2024** : **Devin** - premier agent dÃ©veloppeur IA
- **2025** : IntÃ©gration massive des agents dans les IDE (Cursor, Augment, Windsurf)

**DÃ©finition d'un agent IA :**

> Un **agent IA** est un systÃ¨me d'intelligence artificielle capable de percevoir son environnement, de raisonner sur ses objectifs, de planifier des actions, et d'exÃ©cuter ces actions de maniÃ¨re autonome pour atteindre ses buts.

### 1.9 Chronologie synthÃ©tique

```mermaid
timeline
    title Ã‰volution de l'Intelligence Artificielle
    section Origines
        1943 : Premier modÃ¨le de neurone artificiel (McCulloch & Pitts)
        1950 : Test de Turing (Alan Turing)
        1956 : ConfÃ©rence de Dartmouth - Naissance de l'IA
    section Ã‚ge d'or
        1961 : Unimate - Premier robot industriel
        1966 : ELIZA - Premier chatbot
        1969 : Shakey - Premier robot mobile autonome
    section Hivers de l'IA
        1974 : Premier hiver de l'IA
        1980 : SystÃ¨mes experts (MYCIN, R1/XCON)
        1987 : DeuxiÃ¨me hiver de l'IA
    section Renaissance
        1997 : Deep Blue bat Kasparov
        2006 : Renaissance du Deep Learning (Hinton)
        2012 : AlexNet rÃ©volutionne la vision par ordinateur
    section RÃ©volution LLM
        2016 : AlphaGo bat Lee Sedol
        2017 : Architecture Transformer
        2022 : ChatGPT - IA conversationnelle grand public
    section Ãˆre Agentique
        2023 : Ã‰mergence des agents IA autonomes
        2024 : Agents IA intÃ©grÃ©s dans les outils de dÃ©veloppement
        2025 : IA agentique gÃ©nÃ©ralisÃ©e
```

---

## 2. Fonctionnement des agents IA

### 2.1 Concepts fondamentaux

#### Qu'est-ce qu'un agent ?

En intelligence artificielle, un **agent** est une entitÃ© qui :

1. **PerÃ§oit** son environnement via des capteurs (ou entrÃ©es)
2. **Raisonne** sur ces perceptions et ses objectifs
3. **Agit** sur l'environnement via des effecteurs (ou sorties)

**Analogie robotique :**

| Composant | Robot physique | Agent IA |
|-----------|----------------|----------|
| Capteurs | CamÃ©ras, LIDAR, IMU | APIs, fichiers, bases de donnÃ©es |
| Traitement | MicrocontrÃ´leur, CPU | LLM (Large Language Model) |
| Effecteurs | Moteurs, pinces | Appels d'outils, gÃ©nÃ©ration de code |
| Environnement | Monde physique | SystÃ¨me informatique, web |

#### Types d'agents

**1. Agents rÃ©actifs simples :**
- RÃ©pondent directement aux stimuli
- Pas de mÃ©moire ni de planification
- Exemple : thermostat, chatbot basique

**2. Agents basÃ©s sur des modÃ¨les :**
- Maintiennent un modÃ¨le interne du monde
- Peuvent gÃ©rer des environnements partiellement observables
- Exemple : robot avec carte de l'environnement

**3. Agents basÃ©s sur des objectifs :**
- Ont des buts explicites Ã  atteindre
- Planifient des sÃ©quences d'actions
- Exemple : agent de navigation GPS

**4. Agents basÃ©s sur l'utilitÃ© :**
- Optimisent une fonction d'utilitÃ©
- GÃ¨rent les compromis entre objectifs
- Exemple : agent de trading

**5. Agents apprenants :**
- S'amÃ©liorent avec l'expÃ©rience
- Adaptent leur comportement
- Exemple : AlphaGo, agents IA modernes

### 2.2 Le cycle perception-dÃ©cision-action

#### Boucle fondamentale

Tout agent IA fonctionne selon un cycle continu :

```mermaid
flowchart TB
    subgraph ENV["ğŸŒ ENVIRONNEMENT"]
        Data["DonnÃ©es & Stimuli"]
    end

    subgraph AGENT["ğŸ¤– AGENT"]
        direction LR
        Percevoir["ğŸ” Percevoir"]
        Decider["ğŸ§  DÃ©cider"]
        Agir["âš¡ Agir"]
        Memoire["ğŸ’¾ MÃ©moire"]

        Percevoir --> Decider
        Decider --> Agir
        Decider <--> Memoire
    end

    ENV -->|"Perception"| Percevoir
    Agir -->|"Action"| ENV
```

**Ã‰tapes du cycle :**

1. **Perception** : L'agent reÃ§oit des informations de son environnement
2. **InterprÃ©tation** : Les donnÃ©es brutes sont transformÃ©es en reprÃ©sentations utilisables
3. **Raisonnement** : L'agent analyse la situation et ses objectifs
4. **Planification** : Une sÃ©quence d'actions est Ã©laborÃ©e
5. **ExÃ©cution** : Les actions sont effectuÃ©es
6. **Observation** : Les rÃ©sultats sont Ã©valuÃ©s
7. **Apprentissage** : L'agent met Ã  jour ses connaissances

### 2.3 Architecture d'un agent IA moderne

#### Composants principaux

**1. Le modÃ¨le de langage (LLM) - Le "cerveau"**

Le LLM est le cÅ“ur de l'agent moderne :
- Comprend le langage naturel
- Raisonne sur les problÃ¨mes
- GÃ©nÃ¨re des plans d'action
- Produit du texte, du code, des commandes

**Exemples de LLM :**
- GPT-4, GPT-4o (OpenAI)
- Claude 3.5 Sonnet, Claude Opus (Anthropic)
- Gemini (Google)
- Llama 3 (Meta)
- Mistral (Mistral AI)

**2. La mÃ©moire**

Les agents modernes utilisent plusieurs types de mÃ©moire :

| Type | Description | Exemple |
|------|-------------|---------|
| **MÃ©moire de travail** | Contexte de la conversation actuelle | Messages rÃ©cents |
| **MÃ©moire Ã  court terme** | Informations de la session | Variables, Ã©tat |
| **MÃ©moire Ã  long terme** | Connaissances persistantes | Base vectorielle |
| **MÃ©moire Ã©pisodique** | ExpÃ©riences passÃ©es | Historique des actions |
| **MÃ©moire sÃ©mantique** | Connaissances gÃ©nÃ©rales | Documentation, faits |

**3. Les outils (Tools)**

Les outils Ã©tendent les capacitÃ©s de l'agent :

- **Recherche web** : accÃ¨s Ã  l'information en temps rÃ©el
- **ExÃ©cution de code** : calculs, scripts, automatisation
- **AccÃ¨s aux fichiers** : lecture, Ã©criture, modification
- **APIs externes** : services tiers, bases de donnÃ©es
- **ContrÃ´le systÃ¨me** : commandes shell, processus

**4. Le systÃ¨me de planification**

Permet Ã  l'agent de :
- DÃ©composer les tÃ¢ches complexes
- Ordonner les sous-tÃ¢ches
- GÃ©rer les dÃ©pendances
- Adapter le plan en cours d'exÃ©cution

### 2.4 Utilisation des outils (Function Calling)

#### Principe du Function Calling

Le **function calling** (ou tool use) permet au LLM d'invoquer des fonctions externes :

**Processus :**

1. L'utilisateur pose une question ou donne une tÃ¢che
2. Le LLM analyse et dÃ©termine qu'un outil est nÃ©cessaire
3. Le LLM gÃ©nÃ¨re un appel de fonction structurÃ© (JSON)
4. Le systÃ¨me exÃ©cute la fonction
5. Le rÃ©sultat est renvoyÃ© au LLM
6. Le LLM intÃ¨gre le rÃ©sultat dans sa rÃ©ponse

**Exemple de dÃ©finition d'outil :**

```json
{
  "name": "lire_capteur_temperature",
  "description": "Lit la tempÃ©rature actuelle d'un capteur du robot",
  "parameters": {
    "type": "object",
    "properties": {
      "capteur_id": {
        "type": "string",
        "description": "Identifiant du capteur (ex: 'temp_moteur_1')"
      },
      "unite": {
        "type": "string",
        "enum": ["celsius", "fahrenheit", "kelvin"],
        "description": "UnitÃ© de tempÃ©rature souhaitÃ©e"
      }
    },
    "required": ["capteur_id"]
  }
}
```

**Exemple d'appel gÃ©nÃ©rÃ© par le LLM :**

```json
{
  "name": "lire_capteur_temperature",
  "arguments": {
    "capteur_id": "temp_moteur_1",
    "unite": "celsius"
  }
}
```

#### Outils courants pour les agents

| CatÃ©gorie | Outils | Usage |
|-----------|--------|-------|
| **Recherche** | web_search, retrieval | Trouver des informations |
| **Code** | execute_code, run_tests | ExÃ©cuter du code |
| **Fichiers** | read_file, write_file | Manipuler des fichiers |
| **SystÃ¨me** | run_command, list_processes | ContrÃ´ler le systÃ¨me |
| **Communication** | send_email, post_message | Interagir avec des services |
| **Robotique** | move_robot, read_sensor | ContrÃ´ler des robots |

### 2.5 Gestion du contexte et de la mÃ©moire

#### La fenÃªtre de contexte

Les LLM ont une **fenÃªtre de contexte limitÃ©e** (nombre maximum de tokens) :

| ModÃ¨le | FenÃªtre de contexte |
|--------|---------------------|
| GPT-3.5 | 16K tokens |
| GPT-4 | 128K tokens |
| Claude 3.5 Sonnet | 200K tokens |
| Gemini 1.5 Pro | 2M tokens |

**StratÃ©gies de gestion :**

1. **RÃ©sumÃ© progressif** : condenser les anciennes conversations
2. **FenÃªtre glissante** : garder les N derniers messages
3. **RÃ©cupÃ©ration sÃ©lective** : chercher les informations pertinentes
4. **HiÃ©rarchisation** : prioriser les informations importantes

#### MÃ©moire vectorielle (RAG)

Le **RAG** (Retrieval-Augmented Generation) permet d'Ã©tendre la mÃ©moire :

**Processus :**

1. **Indexation** : Les documents sont dÃ©coupÃ©s et convertis en vecteurs
2. **Stockage** : Les vecteurs sont stockÃ©s dans une base vectorielle
3. **Recherche** : La requÃªte est convertie en vecteur et comparÃ©e
4. **RÃ©cupÃ©ration** : Les documents les plus similaires sont rÃ©cupÃ©rÃ©s
5. **Augmentation** : Le contexte est enrichi avec ces documents
6. **GÃ©nÃ©ration** : Le LLM rÃ©pond avec ce contexte augmentÃ©

**Bases vectorielles populaires :**
- Pinecone
- Weaviate
- Chroma
- Milvus
- pgvector (PostgreSQL)

### 2.6 Raisonnement et planification

#### CapacitÃ©s de raisonnement

Les agents IA modernes peuvent :

**1. Raisonnement dÃ©ductif :**
- Appliquer des rÃ¨gles logiques
- Tirer des conclusions Ã  partir de prÃ©misses

**2. Raisonnement inductif :**
- GÃ©nÃ©raliser Ã  partir d'exemples
- Identifier des patterns

**3. Raisonnement abductif :**
- InfÃ©rer la meilleure explication
- Formuler des hypothÃ¨ses

**4. Raisonnement analogique :**
- TransfÃ©rer des connaissances entre domaines
- RÃ©soudre par analogie

#### Planification hiÃ©rarchique

Les agents dÃ©composent les tÃ¢ches complexes :

```mermaid
flowchart TB
    Objectif["ğŸ¯ Objectif principal"]

    Objectif --> SO1["ğŸ“‹ Sous-objectif 1"]
    Objectif --> SO2["ğŸ“‹ Sous-objectif 2"]
    Objectif --> SO3["ğŸ“‹ Sous-objectif 3"]

    SO1 --> T11["âœ… TÃ¢che 1.1"]
    SO1 --> T12["âœ… TÃ¢che 1.2"]

    SO2 --> T21["âœ… TÃ¢che 2.1"]
    SO2 --> T22["âœ… TÃ¢che 2.2"]
    SO2 --> T23["âœ… TÃ¢che 2.3"]

    SO3 --> T31["âœ… TÃ¢che 3.1"]
```

**Exemple robotique :**

```mermaid
flowchart TB
    Objectif["ğŸ¯ Objectif : Ranger la piÃ¨ce"]

    Objectif --> Identifier["ğŸ” Identifier les objets Ã  ranger"]
    Objectif --> Planifier["ğŸ“‹ Planifier l'ordre de rangement"]
    Objectif --> Executer["âš¡ ExÃ©cuter le rangement"]

    Identifier --> Scanner["ğŸ“· Scanner la piÃ¨ce avec la camÃ©ra"]
    Identifier --> Classifier["ğŸ·ï¸ Classifier les objets dÃ©tectÃ©s"]

    Planifier --> Prioriser["âš–ï¸ Prioriser par taille/poids"]
    Planifier --> Optimiser["ğŸ—ºï¸ Optimiser les dÃ©placements"]

    Executer --> Saisir["ğŸ¤ Saisir l'objet"]
    Executer --> Naviguer["ğŸš¶ Naviguer vers la destination"]
    Executer --> Deposer["ğŸ“¦ DÃ©poser l'objet"]
```

### 2.7 IntÃ©gration avec les systÃ¨mes externes

#### APIs et services

Les agents peuvent interagir avec :

- **Bases de donnÃ©es** : SQL, NoSQL, GraphQL
- **Services web** : REST APIs, webhooks
- **SystÃ¨mes de fichiers** : local, cloud (S3, GCS)
- **Outils de dÃ©veloppement** : Git, CI/CD
- **Plateformes de communication** : Slack, Discord, email
- **SystÃ¨mes robotiques** : ROS, contrÃ´leurs industriels

#### Exemple d'intÃ©gration robotique

```python
# DÃ©finition d'outils pour un agent robotique
tools = [
    {
        "name": "deplacer_robot",
        "description": "DÃ©place le robot vers une position cible",
        "parameters": {
            "x": "float - coordonnÃ©e X en mÃ¨tres",
            "y": "float - coordonnÃ©e Y en mÃ¨tres",
            "theta": "float - orientation en radians"
        }
    },
    {
        "name": "lire_lidar",
        "description": "Lit les donnÃ©es du capteur LIDAR",
        "parameters": {
            "resolution": "int - nombre de points (dÃ©faut: 360)"
        }
    },
    {
        "name": "activer_pince",
        "description": "Ouvre ou ferme la pince du robot",
        "parameters": {
            "action": "string - 'ouvrir' ou 'fermer'",
            "force": "float - force de prÃ©hension en Newtons"
        }
    }
]
```

---

## 3. Architecture et diagrammes

### 3.1 Architecture gÃ©nÃ©rale d'un agent IA

```mermaid
flowchart TB
    subgraph Utilisateur["ğŸ‘¤ UTILISATEUR"]
        Input["EntrÃ©e utilisateur<br/>(texte, voix, commande)"]
        Output["Sortie<br/>(rÃ©ponse, action)"]
    end

    subgraph Agent["ğŸ¤– AGENT IA"]
        subgraph Perception["Perception"]
            Parser["Analyseur d'entrÃ©e"]
            Context["Gestionnaire de contexte"]
        end

        subgraph Cerveau["Cerveau (LLM)"]
            Reasoning["Raisonnement"]
            Planning["Planification"]
            Decision["Prise de dÃ©cision"]
        end

        subgraph Memory["MÃ©moire"]
            ShortTerm["Court terme"]
            LongTerm["Long terme<br/>(vectorielle)"]
            Episodic["Ã‰pisodique"]
        end

        subgraph Execution["ExÃ©cution"]
            ToolSelector["SÃ©lecteur d'outils"]
            Executor["ExÃ©cuteur"]
            Monitor["Moniteur"]
        end
    end

    subgraph Tools["ğŸ”§ OUTILS"]
        Search["Recherche web"]
        Code["ExÃ©cution code"]
        Files["Fichiers"]
        APIs["APIs externes"]
        Robot["ContrÃ´le robot"]
    end

    subgraph Environment["ğŸŒ ENVIRONNEMENT"]
        Data["DonnÃ©es"]
        Systems["SystÃ¨mes"]
        Physical["Monde physique"]
    end

    Input --> Parser
    Parser --> Context
    Context --> Reasoning
    Reasoning <--> Memory
    Reasoning --> Planning
    Planning --> Decision
    Decision --> ToolSelector
    ToolSelector --> Executor
    Executor --> Tools
    Tools --> Environment
    Environment --> Monitor
    Monitor --> Context
    Decision --> Output
```

### 3.2 Boucle perception-dÃ©cision-action

```mermaid
flowchart LR
    subgraph Cycle["CYCLE DE L'AGENT"]
        direction TB
        
        P["ğŸ” PERCEVOIR<br/>â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€<br/>â€¢ Recevoir les entrÃ©es<br/>â€¢ Lire les capteurs<br/>â€¢ RÃ©cupÃ©rer le contexte"]
        
        I["ğŸ§  INTERPRÃ‰TER<br/>â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€<br/>â€¢ Analyser les donnÃ©es<br/>â€¢ Comprendre l'intention<br/>â€¢ Identifier les besoins"]
        
        R["ğŸ’­ RAISONNER<br/>â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€<br/>â€¢ Ã‰valuer les options<br/>â€¢ Appliquer les rÃ¨gles<br/>â€¢ ConsidÃ©rer les contraintes"]
        
        PL["ğŸ“‹ PLANIFIER<br/>â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€<br/>â€¢ DÃ©composer la tÃ¢che<br/>â€¢ Ordonner les Ã©tapes<br/>â€¢ PrÃ©voir les contingences"]
        
        A["âš¡ AGIR<br/>â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€<br/>â€¢ ExÃ©cuter les actions<br/>â€¢ Appeler les outils<br/>â€¢ Modifier l'environnement"]
        
        O["ğŸ‘ï¸ OBSERVER<br/>â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€<br/>â€¢ VÃ©rifier les rÃ©sultats<br/>â€¢ DÃ©tecter les erreurs<br/>â€¢ Mesurer le succÃ¨s"]
        
        L["ğŸ“š APPRENDRE<br/>â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€<br/>â€¢ Mettre Ã  jour la mÃ©moire<br/>â€¢ Ajuster les stratÃ©gies<br/>â€¢ AmÃ©liorer les modÃ¨les"]
    end
    
    P --> I --> R --> PL --> A --> O --> L --> P
```

### 3.3 Interaction avec les outils

```mermaid
sequenceDiagram
    participant U as ğŸ‘¤ Utilisateur
    participant A as ğŸ¤– Agent (LLM)
    participant T as ğŸ”§ Gestionnaire d'outils
    participant O as âš™ï¸ Outil externe
    participant E as ğŸŒ Environnement

    U->>A: "Quelle est la tempÃ©rature du moteur ?"
    
    Note over A: Analyse de la requÃªte
    Note over A: DÃ©cision : utiliser l'outil capteur
    
    A->>T: Appel fonction : lire_capteur("temp_moteur_1")
    T->>O: ExÃ©cution de la fonction
    O->>E: Lecture du capteur physique
    E-->>O: Valeur : 45.2Â°C
    O-->>T: RÃ©sultat : {"temperature": 45.2, "unite": "celsius"}
    T-->>A: Retour du rÃ©sultat
    
    Note over A: IntÃ©gration du rÃ©sultat
    Note over A: Formulation de la rÃ©ponse
    
    A-->>U: "La tempÃ©rature du moteur est de 45.2Â°C, ce qui est dans la plage normale."
```

### 3.4 Flux d'information dans un systÃ¨me agentique

```mermaid
flowchart TB
    subgraph Input["ENTRÃ‰ES"]
        Text["Texte"]
        Voice["Voix"]
        Sensors["Capteurs"]
        Events["Ã‰vÃ©nements"]
    end

    subgraph Processing["TRAITEMENT"]
        subgraph Preprocessing["PrÃ©traitement"]
            Tokenize["Tokenisation"]
            Embed["Embedding"]
            Normalize["Normalisation"]
        end

        subgraph Core["CÅ“ur de l'agent"]
            LLM["LLM<br/>(Raisonnement)"]
            Memory["MÃ©moire<br/>(Contexte)"]
            Tools["Outils<br/>(CapacitÃ©s)"]
        end

        subgraph Postprocessing["Post-traitement"]
            Parse["Parsing"]
            Validate["Validation"]
            Format["Formatage"]
        end
    end

    subgraph Output["SORTIES"]
        Response["RÃ©ponse texte"]
        Actions["Actions"]
        Commands["Commandes"]
        Logs["Logs"]
    end

    Input --> Preprocessing
    Preprocessing --> Core
    Core --> Postprocessing
    Postprocessing --> Output

    Memory <--> LLM
    Tools <--> LLM
```

### 3.5 Comparaison IA traditionnelle vs IA agentique

```mermaid
flowchart TB
    subgraph Traditional["IA TRADITIONNELLE"]
        direction TB
        T_Input["EntrÃ©e unique"]
        T_Model["ModÃ¨le<br/>(traitement unique)"]
        T_Output["Sortie unique"]
        
        T_Input --> T_Model --> T_Output
    end

    subgraph Agentic["IA AGENTIQUE"]
        direction TB
        A_Input["Objectif"]
        A_Loop["Boucle autonome"]
        A_Tools["Outils multiples"]
        A_Memory["MÃ©moire persistante"]
        A_Output["RÃ©sultat final"]
        
        A_Input --> A_Loop
        A_Loop <--> A_Tools
        A_Loop <--> A_Memory
        A_Loop --> A_Output
        A_Output -.->|"Feedback"| A_Loop
    end

    subgraph Comparison["DIFFÃ‰RENCES CLÃ‰S"]
        direction LR
        C1["âŒ RÃ©ponse unique<br/>âœ… ItÃ©rations multiples"]
        C2["âŒ Pas de mÃ©moire<br/>âœ… Contexte persistant"]
        C3["âŒ CapacitÃ©s fixes<br/>âœ… Outils extensibles"]
        C4["âŒ Passif<br/>âœ… Autonome"]
    end
```

### 3.6 Architecture multi-agents

```mermaid
flowchart TB
    subgraph Orchestrator["ğŸ­ ORCHESTRATEUR"]
        Coordinator["Coordinateur<br/>â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€<br/>â€¢ Distribue les tÃ¢ches<br/>â€¢ GÃ¨re les prioritÃ©s<br/>â€¢ RÃ©sout les conflits"]
    end

    subgraph Agents["ğŸ¤– AGENTS SPÃ‰CIALISÃ‰S"]
        Agent1["Agent Planificateur<br/>â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€<br/>â€¢ DÃ©compose les objectifs<br/>â€¢ CrÃ©e les plans"]
        
        Agent2["Agent ExÃ©cuteur<br/>â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€<br/>â€¢ ExÃ©cute les actions<br/>â€¢ Utilise les outils"]
        
        Agent3["Agent Critique<br/>â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€<br/>â€¢ VÃ©rifie les rÃ©sultats<br/>â€¢ SuggÃ¨re des amÃ©liorations"]
        
        Agent4["Agent Recherche<br/>â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€<br/>â€¢ Trouve l'information<br/>â€¢ SynthÃ©tise les donnÃ©es"]
    end

    subgraph SharedResources["ğŸ“¦ RESSOURCES PARTAGÃ‰ES"]
        SharedMemory["MÃ©moire partagÃ©e"]
        SharedTools["Outils communs"]
        MessageQueue["File de messages"]
    end

    Coordinator <--> Agent1
    Coordinator <--> Agent2
    Coordinator <--> Agent3
    Coordinator <--> Agent4

    Agent1 <--> SharedResources
    Agent2 <--> SharedResources
    Agent3 <--> SharedResources
    Agent4 <--> SharedResources
```

### 3.7 Diagramme spÃ©cifique robotique

```mermaid
flowchart TB
    subgraph RobotAgent["ğŸ¤– AGENT ROBOTIQUE"]
        subgraph Perception["PERCEPTION"]
            Camera["ğŸ“· CamÃ©ra<br/>(Vision)"]
            Lidar["ğŸ“¡ LIDAR<br/>(Distance)"]
            IMU["ğŸ§­ IMU<br/>(Orientation)"]
            Encoders["âš™ï¸ Encodeurs<br/>(Position)"]
        end

        subgraph Brain["CERVEAU IA"]
            VisionAI["Vision par ordinateur<br/>(DÃ©tection, Segmentation)"]
            LLM["LLM<br/>(Raisonnement, Planification)"]
            SLAM["SLAM<br/>(Localisation, Cartographie)"]
            PathPlanning["Planification de trajectoire"]
        end

        subgraph Action["ACTION"]
            Motors["ğŸ”„ Moteurs<br/>(Locomotion)"]
            Gripper["ğŸ¤ Pince<br/>(Manipulation)"]
            Speakers["ğŸ”Š Haut-parleurs<br/>(Communication)"]
        end
    end

    subgraph Environment["ğŸŒ ENVIRONNEMENT"]
        Objects["Objets"]
        Obstacles["Obstacles"]
        Humans["Humains"]
        Goals["Objectifs"]
    end

    Camera --> VisionAI
    Lidar --> SLAM
    IMU --> SLAM
    Encoders --> PathPlanning

    VisionAI --> LLM
    SLAM --> LLM
    LLM --> PathPlanning

    PathPlanning --> Motors
    LLM --> Gripper
    LLM --> Speakers

    Environment <--> Perception
    Action --> Environment
```

---

## 4. Techniques de prompting

### 4.1 Introduction au prompting

#### Qu'est-ce que le prompting ?

Le **prompting** est l'art de formuler des instructions pour les modÃ¨les de langage afin d'obtenir les rÃ©ponses souhaitÃ©es.

**Pourquoi c'est important :**

- Les LLM sont sensibles Ã  la formulation des requÃªtes
- Un bon prompt peut amÃ©liorer drastiquement la qualitÃ© des rÃ©ponses
- Le prompting est une compÃ©tence essentielle pour utiliser l'IA efficacement

**Composants d'un prompt :**

1. **Contexte** : informations de fond
2. **Instruction** : ce que vous voulez que le modÃ¨le fasse
3. **EntrÃ©e** : les donnÃ©es Ã  traiter
4. **Format de sortie** : comment structurer la rÃ©ponse

### 4.2 Principes fondamentaux

#### ClartÃ© et prÃ©cision

**âŒ Mauvais prompt :**
```
Parle-moi des robots.
```

**âœ… Bon prompt :**
```
Explique les trois principaux types de robots industriels 
(articulÃ©s, SCARA, cartÃ©siens), en dÃ©crivant pour chacun :
- Leur structure mÃ©canique
- Leurs applications typiques
- Leurs avantages et inconvÃ©nients

Utilise un format de tableau pour la comparaison.
```

#### SpÃ©cificitÃ©

**âŒ Vague :**
```
Ã‰cris du code pour un robot.
```

**âœ… SpÃ©cifique :**
```
Ã‰cris une fonction Python qui :
- Prend en entrÃ©e les coordonnÃ©es (x, y) d'un point cible
- Calcule l'angle de rotation nÃ©cessaire pour un robot diffÃ©rentiel
- Retourne l'angle en radians
- GÃ¨re le cas oÃ¹ le robot est dÃ©jÃ  Ã  la position cible

Utilise numpy pour les calculs trigonomÃ©triques.
Ajoute des docstrings et des commentaires explicatifs.
```

#### Structure

Utilisez des dÃ©limiteurs clairs :

```
### Contexte ###
Tu es un expert en robotique mobile.

### TÃ¢che ###
Analyse le code suivant et identifie les problÃ¨mes potentiels.

### Code Ã  analyser ###
```python
def move_robot(x, y):
    # code ici
```

### Format de rÃ©ponse ###
Pour chaque problÃ¨me :
1. Ligne concernÃ©e
2. Description du problÃ¨me
3. Solution proposÃ©e
```

### 4.3 Zero-shot prompting

#### DÃ©finition

Le **zero-shot prompting** consiste Ã  demander au modÃ¨le d'effectuer une tÃ¢che sans lui fournir d'exemples.

**Principe :** On fait confiance aux connaissances prÃ©existantes du modÃ¨le.

#### Exemples

**Classification :**
```
Classifie le texte suivant comme "positif", "nÃ©gatif" ou "neutre" :

Texte : "Le nouveau capteur LIDAR offre une prÃ©cision exceptionnelle, 
mais son prix reste prohibitif pour les petits projets."

Classification :
```

**Extraction d'information :**
```
Extrais les spÃ©cifications techniques du texte suivant :

Texte : "Le robot UR5e possÃ¨de une portÃ©e de 850mm, une charge utile 
de 5kg, et une rÃ©pÃ©tabilitÃ© de Â±0.03mm. Il consomme en moyenne 200W."

SpÃ©cifications (format JSON) :
```

**GÃ©nÃ©ration de code :**
```
Ã‰cris une fonction Python qui implÃ©mente un contrÃ´leur PID 
pour le contrÃ´le de vitesse d'un moteur DC.

La fonction doit :
- Accepter les gains Kp, Ki, Kd en paramÃ¨tres
- Maintenir l'Ã©tat interne (erreur intÃ©grale, erreur prÃ©cÃ©dente)
- Retourner la commande de contrÃ´le
```

#### Quand utiliser le zero-shot

- TÃ¢ches simples et bien dÃ©finies
- Quand le modÃ¨le a probablement vu des exemples similaires
- Pour des tests rapides
- Quand vous n'avez pas d'exemples disponibles

### 4.4 Few-shot prompting

#### DÃ©finition

Le **few-shot prompting** fournit quelques exemples au modÃ¨le avant de lui demander d'effectuer la tÃ¢che.

**Principe :** Les exemples guident le modÃ¨le sur le format et le style attendus.

#### Structure

```
Voici comment convertir des commandes en langage naturel en commandes robot :

Exemple 1 :
EntrÃ©e : "Avance de 2 mÃ¨tres"
Sortie : move_forward(distance=2.0)

Exemple 2 :
EntrÃ©e : "Tourne Ã  gauche de 90 degrÃ©s"
Sortie : rotate(angle=-90, unit="degrees")

Exemple 3 :
EntrÃ©e : "Attrape l'objet devant toi"
Sortie : gripper_close(force=10)

Maintenant, convertis cette commande :
EntrÃ©e : "Recule de 50 centimÃ¨tres puis tourne Ã  droite"
Sortie :
```

#### Exemples pratiques

**Formatage de donnÃ©es :**
```
Convertis les mesures de capteurs en format standardisÃ© :

EntrÃ©e : "temp: 25.5C, humidity: 60%"
Sortie : {"temperature": {"value": 25.5, "unit": "celsius"}, "humidity": {"value": 60, "unit": "percent"}}

EntrÃ©e : "distance=1.5m angle=45deg"
Sortie : {"distance": {"value": 1.5, "unit": "meters"}, "angle": {"value": 45, "unit": "degrees"}}

EntrÃ©e : "vitesse: 2.3 m/s, acceleration: 0.5 m/sÂ²"
Sortie :
```

**GÃ©nÃ©ration de documentation :**
```
GÃ©nÃ¨re une docstring pour les fonctions suivantes :

Fonction :
def calculate_distance(x1, y1, x2, y2):
    return math.sqrt((x2-x1)**2 + (y2-y1)**2)

Docstring :
"""
Calcule la distance euclidienne entre deux points 2D.

Args:
    x1 (float): CoordonnÃ©e x du premier point
    y1 (float): CoordonnÃ©e y du premier point
    x2 (float): CoordonnÃ©e x du second point
    y2 (float): CoordonnÃ©e y du second point

Returns:
    float: Distance euclidienne entre les deux points
"""

Fonction :
def normalize_angle(angle):
    while angle > math.pi:
        angle -= 2 * math.pi
    while angle < -math.pi:
        angle += 2 * math.pi
    return angle

Docstring :
```

#### Bonnes pratiques few-shot

1. **Choisir des exemples reprÃ©sentatifs** : couvrir les cas typiques
2. **Varier les exemples** : montrer diffÃ©rentes situations
3. **Garder la cohÃ©rence** : mÃªme format pour tous les exemples
4. **3-5 exemples suffisent** gÃ©nÃ©ralement
5. **Ordonner du simple au complexe** si possible

### 4.5 Chain-of-Thought (CoT) prompting

#### DÃ©finition

Le **Chain-of-Thought prompting** encourage le modÃ¨le Ã  expliciter son raisonnement Ã©tape par Ã©tape.

**Principe :** DÃ©composer le problÃ¨me amÃ©liore la qualitÃ© du raisonnement.

#### Prompt simple vs CoT

**âŒ Sans CoT :**
```
Un robot se dÃ©place Ã  0.5 m/s. Il doit parcourir 10 mÃ¨tres, 
puis tourner de 90Â°, puis parcourir 5 mÃ¨tres. 
Combien de temps cela prend-il si la rotation prend 2 secondes ?

RÃ©ponse :
```

**âœ… Avec CoT :**
```
Un robot se dÃ©place Ã  0.5 m/s. Il doit parcourir 10 mÃ¨tres, 
puis tourner de 90Â°, puis parcourir 5 mÃ¨tres. 
Combien de temps cela prend-il si la rotation prend 2 secondes ?

RÃ©sous ce problÃ¨me Ã©tape par Ã©tape :

1. D'abord, calcule le temps pour parcourir 10 mÃ¨tres
2. Ensuite, ajoute le temps de rotation
3. Puis, calcule le temps pour parcourir 5 mÃ¨tres
4. Enfin, additionne tous les temps

Raisonnement :
```

#### Zero-shot CoT

Ajoutez simplement "RÃ©flÃ©chissons Ã©tape par Ã©tape" :

```
Un bras robotique Ã  3 articulations doit atteindre un point 
situÃ© Ã  (0.5, 0.3, 0.2) mÃ¨tres. Les longueurs des segments 
sont L1=0.3m, L2=0.25m, L3=0.15m. 

Le point est-il atteignable ?

RÃ©flÃ©chissons Ã©tape par Ã©tape.
```

#### Few-shot CoT

```
ProblÃ¨me : Un robot doit naviguer d'un point A(0,0) Ã  B(3,4) 
en Ã©vitant un obstacle circulaire centrÃ© en (1.5, 2) de rayon 0.5m.
Quelle est la distance minimale approximative ?

Raisonnement :
1. Distance directe Aâ†’B = âˆš(3Â² + 4Â²) = âˆš25 = 5m
2. VÃ©rifions si le chemin direct passe par l'obstacle :
   - La ligne Aâ†’B a pour Ã©quation : y = (4/3)x
   - Distance du centre (1.5, 2) Ã  cette ligne :
   - |4(1.5) - 3(2) + 0| / âˆš(16+9) = |6-6| / 5 = 0
   - Le centre est sur la ligne ! Le chemin direct est bloquÃ©.
3. Il faut contourner l'obstacle. Approximation :
   - Chemin = distance avant obstacle + demi-cercle + distance aprÃ¨s
   - â‰ˆ 5m + Ï€(0.5) â‰ˆ 5m + 1.57m â‰ˆ 6.57m

RÃ©ponse : Environ 6.6 mÃ¨tres

---

ProblÃ¨me : Un drone doit livrer un colis de 2kg. Sa capacitÃ© 
de charge est de 3kg et sa batterie permet 20 minutes de vol.
Le trajet aller fait 5km Ã  30km/h. Peut-il faire l'aller-retour ?

Raisonnement :
```

### 4.6 ReAct (Reasoning + Acting)

#### DÃ©finition

**ReAct** combine le raisonnement (Reasoning) et l'action (Acting) dans une boucle itÃ©rative.

**Structure :**
1. **Thought** (PensÃ©e) : Le modÃ¨le rÃ©flÃ©chit Ã  la situation
2. **Action** : Le modÃ¨le dÃ©cide d'une action Ã  effectuer
3. **Observation** : Le rÃ©sultat de l'action est observÃ©
4. RÃ©pÃ©ter jusqu'Ã  la rÃ©solution

#### Format ReAct

```
Question : Quel est l'Ã©tat actuel du robot et peut-il effectuer 
une mission de livraison de 5km ?

Thought 1 : Je dois d'abord vÃ©rifier le niveau de batterie du robot.
Action 1 : check_battery()
Observation 1 : Batterie Ã  75%, autonomie estimÃ©e : 8km

Thought 2 : La batterie semble suffisante pour 5km aller, mais 
je dois vÃ©rifier si le retour est possible (10km total).
L'autonomie de 8km est insuffisante. Je dois vÃ©rifier s'il y a 
une station de recharge sur le trajet.
Action 2 : find_charging_stations(route="current_to_destination")
Observation 2 : Station de recharge trouvÃ©e Ã  4km sur le trajet

Thought 3 : Avec une station Ã  4km, le robot peut :
- Aller jusqu'Ã  la station (4km)
- Recharger
- Continuer jusqu'Ã  destination (1km)
- Revenir Ã  la station (1km)
- Recharger
- Retourner au point de dÃ©part (4km)
C'est faisable avec les recharges.
Action 3 : plan_mission(destination="5km", include_charging=True)
Observation 3 : Mission planifiÃ©e avec 2 arrÃªts de recharge

Thought 4 : La mission est planifiÃ©e et rÃ©alisable.
Action 4 : respond("Le robot peut effectuer la mission avec 2 arrÃªts 
de recharge Ã  la station situÃ©e Ã  4km.")
```

#### ImplÃ©mentation pratique

```python
# Pseudo-code d'un agent ReAct
def react_agent(question, tools, max_iterations=10):
    context = f"Question: {question}\n"
    
    for i in range(max_iterations):
        # GÃ©nÃ©rer pensÃ©e et action
        response = llm.generate(context + f"\nThought {i+1}:")
        thought, action = parse_response(response)
        
        context += f"\nThought {i+1}: {thought}"
        context += f"\nAction {i+1}: {action}"
        
        # ExÃ©cuter l'action
        if action.startswith("respond("):
            return extract_response(action)
        
        observation = execute_tool(action, tools)
        context += f"\nObservation {i+1}: {observation}"
    
    return "Limite d'itÃ©rations atteinte"
```

### 4.7 System prompts vs User prompts

#### System prompt

Le **system prompt** dÃ©finit le comportement global de l'agent :

```
Tu es un assistant expert en robotique industrielle. 

Tes responsabilitÃ©s :
- Aider Ã  diagnostiquer les problÃ¨mes des robots
- SuggÃ©rer des optimisations de trajectoire
- Expliquer les concepts de robotique clairement

Tes contraintes :
- Toujours prioriser la sÃ©curitÃ©
- Demander des clarifications si la situation est ambiguÃ«
- Citer tes sources quand tu donnes des spÃ©cifications techniques

Ton style :
- Professionnel mais accessible
- Utiliser des exemples concrets
- Structurer les rÃ©ponses avec des listes quand appropriÃ©
```

#### User prompt

Le **user prompt** contient la requÃªte spÃ©cifique :

```
Mon robot UR10 fait un bruit inhabituel lors des mouvements 
du joint 3. Le bruit apparaÃ®t surtout en charge (>5kg) et 
lors des accÃ©lÃ©rations rapides. Que dois-je vÃ©rifier ?
```

#### Combinaison efficace

```
[SYSTEM]
Tu es un ingÃ©nieur roboticien senior spÃ©cialisÃ© dans le diagnostic.
Format de rÃ©ponse :
1. HypothÃ¨ses probables (classÃ©es par probabilitÃ©)
2. Tests de diagnostic recommandÃ©s
3. Actions correctives possibles
Utilise ton expertise pour guider l'utilisateur de maniÃ¨re mÃ©thodique.

[USER]
Mon robot UR10 fait un bruit inhabituel lors des mouvements 
du joint 3. Le bruit apparaÃ®t surtout en charge (>5kg) et 
lors des accÃ©lÃ©rations rapides.
```

### 4.8 Bonnes pratiques

#### Structure recommandÃ©e

```markdown
# RÃ´le
Tu es [description du rÃ´le et de l'expertise].

# Contexte
[Informations de fond pertinentes]

# TÃ¢che
[Description claire de ce qui est demandÃ©]

# Contraintes
- [Contrainte 1]
- [Contrainte 2]

# Format de sortie
[Description du format attendu]

# Exemples (si few-shot)
[Exemples]

# EntrÃ©e
[DonnÃ©es Ã  traiter]
```

#### Techniques avancÃ©es

**1. Persona :**
```
Tu es le Dr. Sarah Chen, une experte mondiale en robotique 
humanoÃ¯de avec 20 ans d'expÃ©rience chez Boston Dynamics.
```

**2. Contraintes nÃ©gatives :**
```
NE PAS :
- Inventer des spÃ©cifications techniques
- SuggÃ©rer des modifications non sÃ©curitaires
- Ignorer les normes ISO de sÃ©curitÃ© robotique
```

**3. MÃ©ta-prompting :**
```
Avant de rÃ©pondre, pose-toi ces questions :
1. Ai-je bien compris la demande ?
2. Ma rÃ©ponse est-elle complÃ¨te ?
3. Y a-t-il des risques de sÃ©curitÃ© Ã  considÃ©rer ?
```

**4. DÃ©composition de tÃ¢che :**
```
Pour rÃ©soudre ce problÃ¨me, suis ces Ã©tapes :
1. Analyse les symptÃ´mes dÃ©crits
2. Liste les causes possibles
3. Propose un arbre de diagnostic
4. Recommande les actions par ordre de prioritÃ©
```

### 4.9 Erreurs courantes Ã  Ã©viter

#### âŒ Prompts trop vagues

```
Mauvais : "Aide-moi avec mon robot"
Bon : "Mon robot diffÃ©rentiel ne suit pas correctement les 
trajectoires circulaires. Il dÃ©rive vers l'extÃ©rieur. 
Quelles peuvent Ãªtre les causes ?"
```

#### âŒ Surcharge d'information

```
Mauvais : [3 pages de contexte non pertinent]
Bon : [Contexte minimal mais suffisant]
```

#### âŒ Instructions contradictoires

```
Mauvais : "Sois bref mais donne tous les dÃ©tails"
Bon : "Donne une rÃ©ponse concise (max 200 mots) couvrant 
les points essentiels"
```

#### âŒ Absence de format de sortie

```
Mauvais : "Analyse ce code"
Bon : "Analyse ce code et fournis :
1. Un rÃ©sumÃ© en une phrase
2. Les problÃ¨mes identifiÃ©s (liste)
3. Les corrections suggÃ©rÃ©es (code)"
```

#### âŒ Attentes irrÃ©alistes

```
Mauvais : "Ã‰cris un systÃ¨me de navigation autonome complet"
Bon : "Ã‰cris une fonction de planification A* pour une grille 2D"
```

### 4.10 Tableau rÃ©capitulatif des techniques

| Technique | Quand l'utiliser | Avantages | InconvÃ©nients |
|-----------|------------------|-----------|---------------|
| **Zero-shot** | TÃ¢ches simples, tests rapides | Rapide, pas d'exemples nÃ©cessaires | Moins prÃ©cis |
| **Few-shot** | Format spÃ©cifique requis | Guide le modÃ¨le efficacement | Consomme des tokens |
| **Chain-of-Thought** | ProblÃ¨mes complexes, maths | Meilleur raisonnement | RÃ©ponses plus longues |
| **ReAct** | TÃ¢ches nÃ©cessitant des outils | Combine rÃ©flexion et action | Plus complexe Ã  implÃ©menter |
| **System prompt** | DÃ©finir le comportement global | CohÃ©rence des rÃ©ponses | Peut Ãªtre ignorÃ© parfois |

---

## 5. Applications en robotique

### 5.1 Agents IA pour le contrÃ´le robotique

#### Cas d'usage

**1. Navigation autonome :**
- Planification de trajectoire avec LLM
- Ã‰vitement d'obstacles intelligent
- Adaptation au contexte (foule, mÃ©tÃ©o)

**2. Manipulation d'objets :**
- Reconnaissance et classification
- Planification de saisie
- Adaptation Ã  des objets inconnus

**3. Interaction homme-robot :**
- ComprÃ©hension du langage naturel
- GÃ©nÃ©ration de rÃ©ponses contextuelles
- Apprentissage des prÃ©fÃ©rences utilisateur

**4. Maintenance prÃ©dictive :**
- Analyse des donnÃ©es capteurs
- DÃ©tection d'anomalies
- Recommandations de maintenance

### 5.2 Exemple d'architecture agent-robot

```mermaid
flowchart TB
    subgraph Human["ğŸ‘¤ OPÃ‰RATEUR"]
        Voice["Commande vocale"]
        Gesture["Gestes"]
        Interface["Interface graphique"]
    end

    subgraph AgentLayer["ğŸ¤– COUCHE AGENT IA"]
        NLU["ComprÃ©hension<br/>langage naturel"]
        TaskPlanner["Planificateur<br/>de tÃ¢ches"]
        SafetyMonitor["Moniteur<br/>de sÃ©curitÃ©"]
        LLM["LLM<br/>(Raisonnement)"]
    end

    subgraph RobotLayer["âš™ï¸ COUCHE ROBOT"]
        MotionPlanner["Planificateur<br/>de mouvement"]
        Controller["ContrÃ´leur<br/>temps rÃ©el"]
        Sensors["Capteurs"]
        Actuators["Actionneurs"]
    end

    subgraph Environment["ğŸŒ ENVIRONNEMENT"]
        Objects["Objets"]
        Obstacles["Obstacles"]
        Workspace["Espace de travail"]
    end

    Human --> NLU
    NLU --> LLM
    LLM --> TaskPlanner
    TaskPlanner --> SafetyMonitor
    SafetyMonitor --> MotionPlanner
    MotionPlanner --> Controller
    Controller --> Actuators
    Actuators --> Environment
    Environment --> Sensors
    Sensors --> Controller
    Sensors --> LLM
```

### 5.3 Prompt engineering pour la robotique

#### Exemple : Agent de diagnostic

```
# System Prompt pour un agent de diagnostic robotique

Tu es un systÃ¨me expert en diagnostic de robots industriels.

## Tes capacitÃ©s
- Analyser les donnÃ©es des capteurs en temps rÃ©el
- Identifier les patterns d'anomalies
- Proposer des diagnostics diffÃ©rentiels
- Recommander des actions correctives

## Outils disponibles
- read_sensor(sensor_id) : Lire un capteur
- get_error_logs(time_range) : RÃ©cupÃ©rer les logs d'erreur
- check_calibration(joint_id) : VÃ©rifier la calibration
- run_diagnostic_routine(routine_name) : ExÃ©cuter un test

## Protocole de diagnostic
1. Collecter les symptÃ´mes rapportÃ©s
2. VÃ©rifier les donnÃ©es capteurs pertinentes
3. Analyser les logs d'erreur rÃ©cents
4. Formuler des hypothÃ¨ses
5. Proposer des tests de confirmation
6. Recommander des actions

## Contraintes de sÃ©curitÃ©
- Ne jamais recommander d'opÃ©ration sans arrÃªt du robot
- Toujours vÃ©rifier l'Ã©tat d'urgence avant toute action
- Signaler immÃ©diatement tout risque pour l'opÃ©rateur
```

---

## 6. Ressources et rÃ©fÃ©rences

### 6.1 Livres fondamentaux

| Livre | Auteur(s) | Description |
|-------|-----------|-------------|
| **Artificial Intelligence: A Modern Approach** | Stuart Russell, Peter Norvig | La rÃ©fÃ©rence en IA |
| **Deep Learning** | Ian Goodfellow, Yoshua Bengio, Aaron Courville | Fondamentaux du deep learning |
| **Robotics, Vision and Control** | Peter Corke | Robotique et vision |
| **Probabilistic Robotics** | Sebastian Thrun et al. | Robotique probabiliste |

### 6.2 Ressources en ligne

**Cours :**
- [CS229 - Machine Learning (Stanford)](https://cs229.stanford.edu/)
- [CS231n - Computer Vision (Stanford)](http://cs231n.stanford.edu/)
- [Prompt Engineering Guide](https://www.promptingguide.ai/)

**Documentation :**
- [OpenAI API Documentation](https://platform.openai.com/docs)
- [Anthropic Claude Documentation](https://docs.anthropic.com/)
- [LangChain Documentation](https://python.langchain.com/)

**Tutoriels :**
- [Hugging Face Course](https://huggingface.co/course)
- [DeepLearning.AI Short Courses](https://www.deeplearning.ai/short-courses/)

### 6.3 Frameworks et outils

| Outil | Usage | Lien |
|-------|-------|------|
| **LangChain** | Framework d'agents | langchain.com |
| **AutoGen** | Agents multi-modaux | microsoft.github.io/autogen |
| **CrewAI** | Orchestration multi-agents | crewai.io |
| **Semantic Kernel** | SDK Microsoft pour IA | github.com/microsoft/semantic-kernel |
| **ROS 2** | Framework robotique | ros.org |

### 6.4 CommunautÃ©s

- **Reddit** : r/MachineLearning, r/robotics, r/LocalLLaMA
- **Discord** : Serveurs LangChain, Hugging Face
- **GitHub** : Projets open source d'agents IA
- **arXiv** : Publications de recherche

---

## Annexe : Glossaire

| Terme | DÃ©finition |
|-------|------------|
| **Agent IA** | SystÃ¨me autonome capable de percevoir, raisonner et agir |
| **LLM** | Large Language Model - ModÃ¨le de langage de grande taille |
| **Prompt** | Instruction donnÃ©e Ã  un modÃ¨le de langage |
| **Token** | UnitÃ© de texte (mot ou sous-mot) traitÃ©e par un LLM |
| **Fine-tuning** | Adaptation d'un modÃ¨le prÃ©-entraÃ®nÃ© Ã  une tÃ¢che spÃ©cifique |
| **RAG** | Retrieval-Augmented Generation - GÃ©nÃ©ration augmentÃ©e par rÃ©cupÃ©ration |
| **Embedding** | ReprÃ©sentation vectorielle d'un texte |
| **Function calling** | CapacitÃ© d'un LLM Ã  invoquer des fonctions externes |
| **Context window** | Nombre maximum de tokens qu'un LLM peut traiter |
| **Chain-of-Thought** | Technique de prompting encourageant le raisonnement explicite |
| **ReAct** | Pattern combinant raisonnement et action |
| **Zero-shot** | ExÃ©cution d'une tÃ¢che sans exemples prÃ©alables |
| **Few-shot** | ExÃ©cution d'une tÃ¢che avec quelques exemples |
| **System prompt** | Instructions dÃ©finissant le comportement global d'un agent |
| **Hallucination** | GÃ©nÃ©ration d'informations fausses par un LLM |
